# 数据概述

## 源数据集

数据集名称：京东消费者行为数据

数据来源：https://www.heywhale.com/mw/dataset/610d46f8911b330017477188/file

数据量：183828 条记录，涉及20个字段，包括用户行为，用户信息，商品信息，店铺和品牌信息



## 各字段定义

| Field                  | Type     | Definition   |
| ---------------------- | -------- | ------------ |
| customer_id            | Bigint   | 客户编码     |
| product_id             | Bigint   | 产品编码     |
| action_date            | DateTime | 行为时间     |
| action_id              | Bigint   | 行为编码     |
| type                   | String   | 行为类别     |
| age_range              | Int      | 年龄分段     |
| gender                 | String   | 性别         |
| customer_register_date | Date     | 客户注册日期 |
| customer_level         | Int      | 会员级别     |
| city_level             | Int      | 会员城市级别 |
| brand                  | String   | 产品品牌     |
| shop_id                | Bigint   | 店铺编码     |
| category               | String   | 产品类别     |
| product_market_date    | Date     | 产品上市日期 |
| vender_id              | Bigint   | 商家编码     |
| fans_number            | Int      | 粉丝数       |
| vip_number             | Int      | 会员数       |
| shop_register_date     | Date     | 开店时间     |
| shop_category          | String   | 店铺主营     |
| shop_score             | Float    | 店铺打分     |



##  数值变量

- 虽然上边很多数值型字段，但是有统计意义的仅有：'fans_number', 'vip_number', 'shop_score'
- 日期字段：'action_date', 'customer_register_date', 'product_market_date', 'shop_register_date'



# 数据预处理

- 详细python代码见文件 ：`预处理.ipynb`



## 数据导入

**导入数据库**

- shop_register_date中空值记录为NULL，应先将类型设置为varchar，改成正常空值后再修改该字段类型
- 上述string类型在mysql中存为varchar(255)，

```sql
-- 将shop_register_date中字符串的NULL改成空（null）
UPDATE jd
SET shop_register_date = NULL
WHERE shop_register_date = 'NULL';

-- 修改该列类型
ALTER TABLE jd
MODIFY COLUMN shop_register_date DATE
```



**pandas读取数据**

```python
# 导入数据
original_data = pd.read_excel('JD_data\京东消费者分析数据.xlsx')
data = original_data.copy()
data.shape
```







## 空值

**空值的情况**

- age_range 有 83 个空值，city_level 有 125 个空值，shop_register_date 有 71354 个空值

```python
# 查看空值情况
data.isnull().sum()
```



**空值的处理**

- age_range 和 city_level 的空值由该字段的众数填充
- shop_register_date 暂时不管，在研究店铺相关问题时尽量不用该字段即可

```python
# 填充 age_range 
data['age_range'].value_counts() 			# 5 最多
data['age_range'].fillna(5, inplace=True)
data['age_range'].isnull().sum()   			# 0

# 填充 city_level
data['city_level'].value_counts() 			# 4 最多
data['age_range'].fillna(4, inplace=True)
```



## 重复值

**action_id 字段**

-  照理来说，action_id 应该是主键，表示每个人的行为编号唯一值

- 但是 action_id 却有很多重复值，这些重复的 action_id 对应的record却不是完全重复的，需要寻找新的主键

```python
# action_id 重复但是记录却不完全重复
data['action_id'].value_counts()[0:10]          # action_id = 10439703 有 9176 条记录
data.query('action_id == 10439703').iloc[:5,:]  # action_id 相同但是其他不同

```



**寻找复合主键**

- groupby(['customer_id', 'product_id','type','action_date']) 后仅有 2 条记录, 
	- 这2条记录除了 action_id 其他都一样，action_id 就是个傻逼字段
	- 重复的记录删掉就行
- 这4个字段组成一个复合主键，含义就是：用户 在某个时间 对商品 ，做了什么 

```python
# 用groupby找复合主键
grouped = data.groupby(['customer_id', 'product_id','type','action_date']).size()
grouped[grouped > 1]  # 2条记录

# 细看这2条记录
data.query("customer_id == 767393 and product_id == 86843") # 除了action_id，其他都一样

```



**去重**

```python
# 删除重复值
to_be_drop = data.query("customer_id == 767393 and product_id == 86843").iloc[0]
data.drop(to_be_drop.name, inplace=True)
```



## 异常值探察

- 不只用pandas，会结合使用Excel，Data Wrang（vscode插件）
- 会对所有字段进行探索



**用户行为字段**

- customer_id ：去重后用户数: 140715
- product_id：去重后商品数: 52950
- action_date：从2018-2-1到2018-4-15
- action_id：傻逼东西
- type：5 个类型，后边细说

```python
# 用户数，去重后
print("去重后用户数:",data['customer_id'].nunique())

# 商品数，去重后
print("去重后商品数:",data['product_id'].nunique())

# 时间范围
print("最早日期：",data['action_date'].min().date())
print("最晚日期：",data['action_date'].max().date(),end='\n\n')
```



 **type字段**

- 行为类别，有PageView,Follow,SaveCart,Order,Comment这5种取值
- Order明显比saveCart多，这不符合常理
    - 发现 SaveCart 在 2018-4-8之后才有数据，可能是数据错误，也可能是4-8之后才有购物车功能。
    - 但是 4-8之后每天SaveCart都比除了PV之外的数据高，不太可能是新增的
    - ==需要过滤掉 4-8 之前的数据==
- Follow数较小，应该指的是收藏店铺 ； Comment指的是评论商品，在购买商品之后 ；用户路径时只需要都不需要考虑 

```python
# 行为类型的分布情况
print("行为类型的分布情况")
print(data['type'].value_counts())   # order:10698,SaveCart:2987 

# 新增一列 action_day，表示行为发生的日期
data['action_day']  = data['action_date'].apply(lambda x: x.date())

# 统计每天每个行为的次数
type_count = data.groupby(['action_day', 'type']).size().unstack()
type_count

# 找到有购物车的记录去日期
type_count[type_count['SavedCart'].isnull().apply(lambda x: not x)]    # 2018-04-08之后

# 4-8之后的数据量
from datetime import date
recent_data = data[data['action_day']>=date(2018, 4, 8)]
recent_data.shape[0]  	# 只有20474条
```















# EDA

- 探索的是处理好的数据，对着有问题的数据探来干嘛？



## 用户行为

**customer_id**  

- 客户编码，非主键
- 183828 条数据全部非空



**product_id**

- 商品id
- 183828 条数据全部非空



**action_date**  

- 行为时间
- datetime类型
- 从2018-2-1到2018-4-15日数据



**action_id**

- 行为id，非主键
- 没啥用，





















